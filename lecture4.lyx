#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Lecture Notes}
\rhead{Zhentao Shi}
\end_preamble
\use_default_options false
\begin_modules
theorems-ams-bytype
theorems-ams-extended-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format dvi
\output_sync 1
\output_sync_macro "\synctex=-1"
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing onehalf
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\branch abc
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\branch pf of gamma = 0
\selected 0
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Asymptotics
\end_layout

\begin_layout Standard
Asymptotic theory is concerned about the behavior of statistics when the
 sample size is arbitrarily large.
 It is a useful approximation technique to simplify extremely complicated
 finite-sample analysis.
 
\end_layout

\begin_layout Subsection
Modes of Convergence
\end_layout

\begin_layout Standard
Convergence of a deterministic sequence means that for any 
\begin_inset Formula $c>0$
\end_inset

, there exists an 
\begin_inset Formula $N\left(c\right)$
\end_inset

 such that for all 
\begin_inset Formula $n>N\left(c\right)$
\end_inset

, we have 
\begin_inset Formula $\left|z_{n}-z\right|<c$
\end_inset

.
 We say 
\begin_inset Formula $z$
\end_inset

 is the limit of 
\begin_inset Formula $z_{n}$
\end_inset

, and denote as 
\begin_inset Formula $z_{n}\to z$
\end_inset

.
\end_layout

\begin_layout Standard
In contrast to the convergence of a deterministic sequence, we are interested
 in the convergence of random variables.
 There are various modes of convergence.
 We introduce three of them.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
almost sure convergence: for any 
\begin_inset Formula $e>0$
\end_inset

, we have 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
P\left(\omega:\lim_{n\to\infty}\left|Z_{n}\left(\omega\right)-z\right|<e\right)=1
\]

\end_inset

alternatively, 
\begin_inset Formula $P\left(\limsup_{n\to\infty}\left\{ \left|Z_{n}\left(\omega\right)-z\right|<e\right\} \right)=1$
\end_inset

 or 
\begin_inset Formula $\lim_{n\to\infty}P\left(\omega:\bigcap_{n}^{\infty}\left\{ \left|Z_{n}\left(\omega\right)-z\right|<e\right\} \right)=1$
\end_inset

.
 Equivalently, 
\begin_inset Formula $\lim_{n\to\infty}P\left(\omega:\bigcup_{n}^{\infty}\left\{ \left|Z_{n}\left(\omega\right)-z\right|>e\right\} \right)=0$
\end_inset

.
\end_layout

\begin_layout Plain Layout
Random variable 
\begin_inset Formula $X_{n}\left(u\right)=1\left\{ u\leq\frac{1}{n}\right\} $
\end_inset

, where 
\begin_inset Formula $u\sim Uniform[0,1]$
\end_inset

.
 In this case,
\begin_inset Formula 
\[
P\left(\bigcup_{n}^{\infty}\left\{ \left|X_{n}-0\right|>e\right\} \right)=P\left(X_{n}>e\right)=1/n\to0.
\]

\end_inset

so 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}0$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Convergence in probability: 
\begin_inset Formula $\lim_{n\to\infty}P\left(\omega:\left|Z_{n}\left(\omega\right)-z\right|<c\right)=1.$
\end_inset


\end_layout

\begin_layout Itemize
Squared-mean convergence: 
\begin_inset Formula $\lim_{n\to\infty}E\left[\left(z_{n}-z\right)^{2}\right]=0.$
\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula $z_{n}\left(\omega\right)\in\left\{ 0,1\right\} $
\end_inset

 is a binary variable.
 
\begin_inset Formula $z_{n}=\sqrt{n}$
\end_inset

 with probability 
\begin_inset Formula $1/n$
\end_inset

, and 
\begin_inset Formula $z_{n}=0$
\end_inset

 with probability 
\begin_inset Formula $1-1/n$
\end_inset

.
 Then 
\begin_inset Formula $z_{n}\stackrel{p}{\to}0$
\end_inset

 but 
\begin_inset Formula $z_{n}\stackrel{m.s.}{\nrightarrow}0$
\end_inset

.
\end_layout

\begin_layout Standard
Convergence in probability does not take care what happens on a set with
 small probability.
 Convergence in mean square takes care the average over the entire probability
 space.
 Even at a small probability the value of the random variables deviates
 too much, it may blow away the convergence in squared-mean.
 On the contrary, such deviation does not undermine convergence in probability.
\end_layout

\begin_layout Itemize
Convergence in distribution: 
\begin_inset Formula $x_{n}\stackrel{d}{\to}x$
\end_inset

 if 
\begin_inset Formula $F\left(x_{n}\right)\to F\left(x\right)$
\end_inset

 for each 
\begin_inset Formula $x$
\end_inset

 on which 
\begin_inset Formula $F\left(x\right)$
\end_inset

 is continuous.
\end_layout

\begin_layout Standard
Convergence in distribution is the convergence of CDF, not the random variables
 themselves.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $x\sim N\left(0,1\right)$
\end_inset

.
 If 
\begin_inset Formula $z_{n}=x+1/n$
\end_inset

, then 
\begin_inset Formula $z_{n}\stackrel{p}{\to}x$
\end_inset

 and of course 
\begin_inset Formula $z_{n}\stackrel{d}{\to}x$
\end_inset

.
 However, if 
\begin_inset Formula $z_{n}=-x+1/n$
\end_inset

, or 
\begin_inset Formula $z_{n}=y+1/n$
\end_inset

 where 
\begin_inset Formula $y\sim N\left(0,1\right)$
\end_inset

 is independent of 
\begin_inset Formula $x$
\end_inset

, then 
\begin_inset Formula $z_{n}\stackrel{d}{\to}x$
\end_inset

 but 
\begin_inset Formula $z_{n}\stackrel{p}{\nrightarrow}x$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Law of Large Numbers
\end_layout

\begin_layout Standard
The law of large numbers (LLN) is a collect of probability theorems about
 the convergence in probability of sample means.
 The basic form of the LLN is: the sample average of 
\begin_inset Formula $\left(z_{1},\ldots,z_{n}\right)$
\end_inset

 satisfies 
\begin_inset Formula 
\[
\frac{1}{n}\sum_{i=1}^{n}z_{i}-E\left(\frac{1}{n}\sum_{i=1}^{n}z_{i}\right)\stackrel{p}{\to}0.
\]

\end_inset

Various versions of LLN work under different assumptions about the random
 variables.
 
\end_layout

\begin_layout Standard
The simplest version of LLN utilizes Chebyshev inequality, a simple fact
 from probability theory.
 For any random variable 
\begin_inset Formula $x$
\end_inset

 with finite 
\begin_inset Formula $E\left[x^{2}\right]$
\end_inset

, we have 
\begin_inset Formula 
\[
P\left(\left|x\right|>c\right)\leq E\left[x^{2}\right]/c^{2}
\]

\end_inset

 for any positive constant 
\begin_inset Formula $c$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula $E\left[x^{2}\right]=\int_{\left|x\right|>c}x^{2}dF_{X}+\int_{\left|x\right|\leq c}x^{2}dF_{X}\geq\int_{\left|x\right|>c}x^{2}dF_{X}\geq c\int_{\left|x\right|>c}dF_{X}=c^{2}P\left(\left|x\right|>c\right).$
\end_inset


\end_layout

\begin_layout Itemize
Chebyshev LLN
\end_layout

\begin_layout Itemize
Kolmogorov LLN
\end_layout

\begin_layout Subsection
Central Limit Theorem
\end_layout

\begin_layout Standard
The central limit theorem (CLT) is a collect of probability theorems about
 the convergence in distribution to a normally distributed random variable.
 The basic form of the CLT is: For a sample 
\begin_inset Formula $\left(z_{1},\ldots,z_{n}\right)$
\end_inset

 of 
\emph on
zero-mean
\emph default
 random variables, the sample mean scaled up by 
\begin_inset Formula $\sqrt{n}$
\end_inset

 satisfies 
\begin_inset Formula 
\[
\frac{1}{\sqrt{n}}\sum_{i=1}^{n}z_{i}\stackrel{d}{\to}N\left(0,\sigma^{2}\right).
\]

\end_inset

Various versions of CLT work under different assumptions about the random
 variables.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\varphi_{x}\left(t\right)=E\left[\exp\left(ixt\right)\right]$
\end_inset

 be the characteristic function.
 If 
\begin_inset Formula $E\left[\left|x\right|^{k}\right]<\infty$
\end_inset

 for a positive integer 
\begin_inset Formula $k$
\end_inset

, then 
\begin_inset Formula 
\[
\varphi_{x}\left(t\right)=1+itE\left[X\right]+\frac{\left(it\right)^{2}}{2}E\left[X^{2}\right]+\ldots\frac{\left(it\right)^{k}}{k!}E\left[X^{k}\right]+o\left(t^{k}\right).
\]

\end_inset

Therefore, if 
\begin_inset Formula $x_{i}$
\end_inset

's mean is zero and variance is 
\begin_inset Formula $\sigma^{2}$
\end_inset

, then 
\begin_inset Formula $\varphi_{x_{i}}\left(t\right)=1-\frac{\sigma^{2}}{2}t^{2}+o\left(\frac{\sigma^{2}}{2}t^{2}\right)$
\end_inset

.
 If the observations in the sample are independent, then 
\begin_inset Formula 
\[
\varphi_{\frac{1}{\sqrt{n}}\sum_{i=1}^{n}x_{i}}\left(t\right)=\left(1-\frac{\sigma^{2}}{2n}t^{2}+o\left(\frac{\sigma^{2}}{2n}t^{2}\right)\right)^{n}\to\exp\left(-\frac{\sigma^{2}}{2}t^{2}\right),
\]

\end_inset

where the limit is exactly the characteristic function of 
\begin_inset Formula $N\left(0,\sigma^{2}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Lindeberg-Levy CLT: iid, zero-mean, finite 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
Lindeberg-Feller CLT: inid, and Lindeberg condition: for any fixed 
\begin_inset Formula $\varepsilon>0$
\end_inset

, 
\begin_inset Formula 
\[
\frac{1}{s_{n}}\sum_{i=1}^{n}\int_{x_{i}^{2}>\varepsilon s_{n}}x_{i}^{2}dPx_{i}\to0
\]

\end_inset

where 
\begin_inset Formula $s_{n}=\sum_{i=1}^{n}\sigma_{i}^{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
Lyapunov CLT: inid, finite 
\begin_inset Formula $E\left[\left|x\right|^{3}\right]$
\end_inset

.
\end_layout

\begin_layout Subsection
Tools for Transformations
\end_layout

\begin_layout Standard
The original forms of LLN or CLT only deal with sample means.
 However, most of the econometric estimators of interest are functions of
 sample means.
 Therefore, we need tools to handle transformations.
\end_layout

\begin_layout Itemize
Small op: 
\begin_inset Formula $x_{n}=o_{p}\left(r_{n}\right)$
\end_inset

 if 
\begin_inset Formula $x_{n}/r_{n}\stackrel{p}{\to}0$
\end_inset

.
\end_layout

\begin_layout Itemize
Big Op: 
\begin_inset Formula $x_{n}=O_{p}\left(r_{n}\right)$
\end_inset

 if for any 
\begin_inset Formula $\varepsilon>0$
\end_inset

, there exists a 
\begin_inset Formula $c>0$
\end_inset

 such that 
\begin_inset Formula $P\left(x_{n}/r_{n}>c\right)<\varepsilon$
\end_inset

.
\end_layout

\begin_layout Itemize
Continuous mapping theorem 1: If 
\begin_inset Formula $x_{n}\stackrel{p}{\to}a$
\end_inset

 and 
\begin_inset Formula $f\left(\cdot\right)$
\end_inset

 is continuous at 
\begin_inset Formula $a$
\end_inset

, then 
\begin_inset Formula $f\left(x_{n}\right)\stackrel{p}{\to}f\left(a\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Continuous mapping theorem 2: If 
\begin_inset Formula $x_{n}\stackrel{d}{\to}x$
\end_inset

 and 
\begin_inset Formula $f\left(\cdot\right)$
\end_inset

 is continuous almost surely on the support of 
\begin_inset Formula $x$
\end_inset

, then 
\begin_inset Formula $f\left(x_{n}\right)\stackrel{d}{\to}f\left(x\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Delta method: if 
\begin_inset Formula $\sqrt{n}\left(\widehat{\theta}-\theta_{0}\right)\stackrel{d}{\to}N\left(0,\Omega\right)$
\end_inset

, and 
\begin_inset Formula $f\left(\cdot\right)$
\end_inset

 is continuously differentiable at 
\begin_inset Formula $\theta_{0}$
\end_inset

, then 
\begin_inset Formula 
\[
\sqrt{n}\left(f\left(\widehat{\theta}\right)-f\left(\theta_{0}\right)\right)\stackrel{d}{\to}N\left(0,\frac{\partial f}{\partial\theta'}\left(\theta\right)\Omega\left(\frac{\partial f}{\partial\theta}\left(\theta\right)\right)'\right).
\]

\end_inset


\end_layout

\begin_layout Section
Apply Asymptotics to OLS
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
CLT
\end_layout

\begin_layout Plain Layout
Lindeberg-Feller CLT
\end_layout

\begin_layout Plain Layout
Lindeberg-Levy CLT is a special case of Lindeberg-Feller by directly checking
 the Lindeberg condition, but not the Lyapunov condition.
\end_layout

\end_inset

Convergence in probability: 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\stackrel{p}{\to}Q=E\left[x_{i}x_{i}'\right]$
\end_inset

, and 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}x_{i}e_{i}\stackrel{p}{\to}0$
\end_inset

.
 By the continuous mapping theorem, 
\begin_inset Formula $\widehat{\beta}-\beta\stackrel{p}{\to}Q^{-1}0=0$
\end_inset

.
\end_layout

\begin_layout Standard
Asymptotic distribution: 
\begin_inset Formula $n^{-1/2}\sum_{i=1}^{n}x_{i}e_{i}\stackrel{d}{\to}N\left(0,\Sigma\right)$
\end_inset

 where 
\begin_inset Formula $\Sigma=E\left[x_{i}x_{i}'e_{i}^{2}\right]$
\end_inset

, so
\begin_inset Formula 
\[
\sqrt{n}\left(\widehat{\beta}-\beta\right)\stackrel{d}{\to}N\left(0,Q^{-1}\Sigma Q^{-1}\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Estimation of the Variance
\end_layout

\begin_layout Standard
To show the finiteness of the variance, 
\begin_inset Formula $\Sigma=E\left[x_{i}x_{i}'e_{i}^{2}\right].$
\end_inset

 Let 
\begin_inset Formula $z_{i}=x_{i}e_{i}$
\end_inset

, so 
\begin_inset Formula $\Omega=E\left[z_{i}z_{i}'\right]$
\end_inset

.
 Because of the Cachy-Schwarz inequality, 
\begin_inset Formula 
\[
\left\Vert \Sigma\right\Vert _{\infty}=\max_{k=1,\ldots,K}E\left[z_{ik}^{2}\right].
\]

\end_inset

For each 
\begin_inset Formula $k$
\end_inset

, 
\begin_inset Formula $E\left[z_{ik}^{2}\right]=E\left[z_{ik}^{2}e_{i}^{2}\right]\leq\left(E\left[z_{ik}^{4}\right]E\left[e_{i}^{4}\right]\right)^{1/2}$
\end_inset

.
\end_layout

\begin_layout Standard
For the estimation of variance, homoskedastic,
\begin_inset Formula 
\[
\frac{1}{n}\sum_{i=1}^{n}\left(e_{i}+x_{i}'\left(\widehat{\beta}-\beta\right)\right)^{2}=\frac{1}{n}\sum_{i=1}^{n}e_{i}^{2}+\left(\frac{2}{n}\sum_{i=1}^{n}e_{i}x_{i}\right)'\left(\widehat{\beta}-\beta\right)+\frac{1}{n}\sum_{i=1}^{n}e_{i}^{2}\left(\widehat{\beta}-\beta\right)'x_{i}x_{i}'\left(\widehat{\beta}-\beta\right)
\]

\end_inset

The second term
\begin_inset Formula 
\[
\left(\frac{2}{n}\sum_{i=1}^{n}e_{i}x_{i}\right)'\left(\widehat{\beta}-\beta\right)=o_{p}\left(1\right)o_{p}\left(1\right)=o_{p}\left(1\right).
\]

\end_inset

The third term
\begin_inset Formula 
\[
\left(\widehat{\beta}-\beta\right)\left(\frac{1}{n}\sum_{i=1}^{n}e_{i}^{2}x_{i}x'_{i}\right)\left(\widehat{\beta}-\beta\right)=o_{p}\left(1\right)O_{p}\left(1\right)o_{p}\left(1\right)=o_{p}\left(1\right).
\]

\end_inset

As 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}\widehat{e}_{i}^{2}=\frac{1}{n}\sum_{i=1}^{n}\widehat{e}_{i}^{2}+o_{p}\left(1\right)$
\end_inset

 and 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}e_{i}^{2}=\sigma_{e}^{2}+o_{p}\left(1\right)$
\end_inset

, we have 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}\widehat{e}_{i}^{2}=\sigma_{e}^{2}+o_{p}\left(1\right)$
\end_inset

.
 In other words, 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}\widehat{e}_{i}^{2}\stackrel{p}{\to}\sigma_{e}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Subsection
Asymptotic Distribution of Functional of Parameters
\end_layout

\begin_layout Plain Layout
A linear restriction that leads to the Wald test.
\end_layout

\begin_layout Plain Layout
Hansen's textbook provides a few examples why we are interested in a function
 of parameters.
 For example, the optimal experience level of a worker.
 We derive the distribution by the delta method.
 It is particularly easy if the parameter of interest is of one dimensional.
 
\end_layout

\begin_layout Plain Layout
Besides point estimator, we might be interested in the interval estimator
 
\begin_inset Formula $C_{n}$
\end_inset

.
 What want to construct 
\begin_inset Formula $\widehat{C}_{n}$
\end_inset

 such that 
\begin_inset Formula 
\[
\lim_{n\to\infty}P\left(\beta_{0}\in\widehat{C}_{n}\right)=1-\alpha.
\]

\end_inset

If we construct 
\begin_inset Formula $\widehat{C}_{n}=\left[\widehat{\beta}-1.96\widehat{\sigma}_{\beta},\widehat{\beta}+1.96\widehat{\sigma}\right]$
\end_inset

, then we have 
\begin_inset Formula 
\[
P\left(\widehat{\beta}-1.96\widehat{\sigma}\leq\beta_{0}\leq\widehat{\beta}+1.96\widehat{\sigma}\right)=P\left(1.96\leq\frac{\widehat{\beta}-\beta_{0}}{\widehat{\sigma}}\leq1.96\right)=F_{n}\left(1.96\right)-F_{n}\left(-1.96\right)\to\Phi\left(1.96\right)-\Phi\left(-1.96\right).
\]

\end_inset


\end_layout

\begin_layout Plain Layout
If multiple dimension, then one way to construct the interval is 
\begin_inset Formula 
\[
P\left(\theta:\left(\widehat{\beta}-\beta\right)V^{-1}\left(\widehat{\beta}-\beta\right)\leq q_{\chi^{2}}\right)
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
Appendix
\end_layout

\begin_layout Standard
For general heteroskedasticity,
\begin_inset Formula 
\[
\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\left(e_{i}+x_{i}'\left(\widehat{\beta}-\beta\right)\right)^{2}=\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'e_{i}^{2}+\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}e_{i}x_{i}'\left(\widehat{\beta}-\beta\right)+\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\left(\left(\widehat{\beta}-\beta\right)'x_{i}\right)^{2}
\]

\end_inset

The third term is bounded by 
\begin_inset Formula 
\begin{eqnarray*}
 &  & \mbox{trace}\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\left(\left(\widehat{\beta}-\beta\right)'x_{i}\right)^{2}\right)\\
 & \leq & K\max_{k}\frac{1}{n}\sum_{i=1}^{n}x_{ik}^{2}\left[\left(\widehat{\beta}-\beta\right)'x_{i}\right]^{2}\leq K\left\Vert \widehat{\beta}-\beta\right\Vert _{2}^{2}\max_{k}\frac{1}{n}\sum_{i=1}^{n}x_{ik}^{2}\left\Vert x_{i}\right\Vert _{2}^{2}\leq K\left\Vert \widehat{\beta}-\beta\right\Vert _{2}^{2}\frac{1}{n}\sum_{i=1}^{n}\left\Vert x_{i}\right\Vert _{2}^{2}\left\Vert x_{i}\right\Vert _{2}^{2}\\
 & = & K\left\Vert \widehat{\beta}-\beta\right\Vert _{2}^{2}\frac{1}{n}\sum_{i=1}^{n}\left(\sum_{k=1}^{K}x_{ik}^{2}\right)^{2}\leq K\left\Vert \widehat{\beta}-\beta\right\Vert _{2}^{2}K\sum_{k=1}^{K}\frac{1}{n}\sum_{i=1}^{n}x_{ik}^{4}=o_{p}\left(1\right)O_{p}\left(1\right)=o_{p}\left(1\right).
\end{eqnarray*}

\end_inset

where the third inequality follows by 
\begin_inset Formula $\left(a_{1}+\cdots+a_{K}\right)^{2}\leq K\left(a_{1}^{2}+\cdots+a_{K}^{2}\right)$
\end_inset

.
 The second term is bounded by 
\begin_inset Formula 
\begin{eqnarray*}
\left|\frac{1}{n}\sum_{i=1}^{n}x_{ik}x_{ik'}e_{i}x_{i}'\left(\widehat{\beta}-\beta\right)\right| & \leq & \max_{k}\left|\widehat{\beta}_{k}-\beta_{k}\right|K\max_{k,k',k''}\left|\frac{1}{n}\sum_{i=1}^{n}e_{i}x_{ik}x_{ik'}x_{ik''}\right|\\
 & \leq & \left\Vert \widehat{\beta}-\beta\right\Vert _{2}\left(\frac{1}{n}\sum_{i=1}^{n}e_{i}^{4}\right)^{1/4}K\max_{k,k',k''}\left(\frac{1}{n}\sum_{i=1}^{n}\left(x_{ik}x_{ik'}x_{ik''}\right)^{4/3}\right)^{3/4}\\
 & \leq & \left\Vert \widehat{\beta}-\beta\right\Vert _{2}K\max_{k}\left(\frac{1}{n}\sum_{i=1}^{n}x_{ik}^{4}\right)^{3/4}=o_{p}\left(1\right)O_{p}\left(1\right)
\end{eqnarray*}

\end_inset

where the second and the third inequality hold by the Holder's inequality.
 
\end_layout

\end_body
\end_document
