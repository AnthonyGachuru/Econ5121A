#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\renewcommand\theenumi{(\alph{enumi})}
\renewcommand\labelenumi{\theenumi}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams-bytype
theorems-ams-extended-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format dvi
\output_sync 1
\output_sync_macro "\synctex=-1"
\bibtex_command default
\index_command default
\paperfontsize default
\spacing double
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1.5in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Some Facts about Joint Normal Distribution
\end_layout

\begin_layout Author
Zhentao Shi
\end_layout

\begin_layout Date
2/1/2012
\end_layout

\begin_layout Standard
It is arguable that normal distribution is the most frequently encountered
 distribution in statistical inference, as it is the asymptotic distribution
 of many popular estimators.
 Moreover, it boasts some unique features that facilitates the calculation
 of objects of interest.
 This note summaries a few of them.
\end_layout

\begin_layout Standard
An 
\begin_inset Formula $n\times1$
\end_inset

 random vector 
\begin_inset Formula $X$
\end_inset

 follows a joint normal distribution 
\begin_inset Formula $N\left(\mu,\Sigma\right)$
\end_inset

, where 
\begin_inset Formula $\mu$
\end_inset

 is a 
\begin_inset Formula $n\times1$
\end_inset

 vector and 
\begin_inset Formula $\Sigma$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 symmetric positive definite matrix.
 The probability density function is
\begin_inset Formula 
\[
f_{X}\left(x\right)=\left(2\pi\right)^{-n/2}\left(\mathrm{det}\left(\Sigma\right)\right)^{-1/2}\exp\left(-\frac{1}{2}\left(x-\mu\right)'\Sigma^{-1}\left(x-\mu\right)\right)
\]

\end_inset

 and the moment generating function is
\begin_inset Formula 
\[
M_{X}\left(t\right)=\exp\left(t'\mu+\frac{1}{2}t'\Sigma t\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Theorem 1 states the fact that a linear transformation of 
\begin_inset Formula $X$
\end_inset

 still follows a joint normal distribution.
 
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X\sim N\left(\mu,\Sigma\right)$
\end_inset

, then 
\begin_inset Formula $Y:=AX+b\sim N\left(A\mu+b,A\Sigma A'\right)$
\end_inset

.
\end_layout

\begin_layout Standard
We will discuss the relationship between two components of a random vector.
 To fix notation,
\begin_inset Formula 
\[
X=\left(\begin{array}{c}
X_{1}\\
X_{2}
\end{array}\right)\sim N\left(\left(\begin{array}{c}
\mu_{1}\\
\mu_{2}
\end{array}\right),\left(\begin{array}{cc}
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}
\end{array}\right)\right)
\]

\end_inset

where 
\begin_inset Formula $X_{1}$
\end_inset

 is a 
\begin_inset Formula $m\times1$
\end_inset

 vector, and 
\begin_inset Formula $X_{2}$
\end_inset

 is a 
\begin_inset Formula $\left(n-m\right)\times1$
\end_inset

 vector.
 
\begin_inset Formula $\mu_{1}$
\end_inset

 and 
\begin_inset Formula $\mu_{2}$
\end_inset

 are the corresponding mean vectors, and 
\begin_inset Formula $\Sigma_{ij}$
\end_inset

, 
\begin_inset Formula $j=1,2$
\end_inset

 are the corresponding variance and covariance matrices.
 From now on, we always maintain the assumption that 
\begin_inset Formula $X=\left(\begin{array}{c}
X_{1}\\
X_{2}
\end{array}\right)$
\end_inset

 is jointly normal.
\end_layout

\begin_layout Standard
Theorem 1 immediately implies a convenient feature of the normal distribution.
 Generally speaking, if we are given a joint pdf of two random variables
 and intend to find the marginal distribution of one random variables, we
 need to integrate out the other variable from the joint pdf.
 However, if the variables are jointly normal, the information of the other
 random variable is irrelevant to the marginal distribution of the random
 variable of interest.
 We only need to know the partial information of the part of interest, say
 the mean 
\begin_inset Formula $\mu_{1}$
\end_inset

 and the variance 
\begin_inset Formula $\Sigma_{11}$
\end_inset

 to decide the marginal distribution of 
\begin_inset Formula $X_{1}$
\end_inset

.
\end_layout

\begin_layout Theorem
The marginal distribution 
\begin_inset Formula $X_{1}\sim N\left(\mu_{1},\Sigma_{11}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
This result is very convenient if we are interested in some component if
 an estimator, but not the entire vector of the estimator.
 For example, the OLS estimator of the linear regression model 
\begin_inset Formula $y=Z\beta+\epsilon$
\end_inset

, under the commonly used assumptions, is
\begin_inset Formula 
\[
\widehat{\beta}_{n}=\left(Z'Z\right)^{-1}Z'y,
\]

\end_inset

and the asymptotic distribution of 
\begin_inset Formula $\widehat{\beta}_{n}$
\end_inset

 is 
\begin_inset Formula 
\[
\sqrt{n}\left(\widehat{\beta}_{n}-\beta_{0}\right)\stackrel{\mathrm{d}}{\to}N\left(0,\left(Z'Z\right)^{-1}\sigma^{2}\right)
\]

\end_inset

where 
\begin_inset Formula $\beta_{0}$
\end_inset

 is the true parameter.
 If we are interested in the inference of only the 
\begin_inset Formula $j$
\end_inset

-th component of 
\begin_inset Formula $\beta_{0}^{\left(j\right)}$
\end_inset

, then from Theorem 2,
\begin_inset Formula 
\[
\sqrt{n}\left(\widehat{\beta}_{n}^{\left(j\right)}-\beta_{0}^{\left(j\right)}\right)\stackrel{\mathrm{d}}{\to}N\left(0,\left(Z'Z\right)_{jj}^{-1}\sigma^{2}\right)
\]

\end_inset

where 
\begin_inset Formula $\left(Z'Z\right)_{jj}^{-1}$
\end_inset

 is the 
\begin_inset Formula $j$
\end_inset

-th diagonal element of 
\begin_inset Formula $\left(Z'Z\right)^{-1}$
\end_inset

.
 The marginal distribution is independent of the other components.
 This saves us from integrating out the other components, which could be
 troublesome if the dimension of the vector is high.
\end_layout

\begin_layout Standard
Again, generally zero covariance of two random variables only indicates
 that they are uncorrelated, whereas full independence is a much stronger
 requirement.
 However, if 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are jointly normal, then zero covariance is equivalent to full independence.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $\Sigma_{12}=0$
\end_inset

, then 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are independent.
\end_layout

\begin_layout Standard
The last result, which is useful in linear regression, is that if 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are jointly normal, the conditional distribution of 
\begin_inset Formula $X_{1}$
\end_inset

 on 
\begin_inset Formula $X_{2}$
\end_inset

 is still jointly normal, with the mean and variance specified as in the
 following theorem.
 This is the general formula for the calculation of Question 2 of Problem
 Set 1.
\end_layout

\begin_layout Theorem
\begin_inset Formula $X_{1}|X_{2}\sim N\left(\mu_{1}+\Sigma_{12}\Sigma_{22}^{-1}\left(X_{2}-\mu_{2}\right),\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}\right)$
\end_inset

.
\end_layout

\end_body
\end_document
